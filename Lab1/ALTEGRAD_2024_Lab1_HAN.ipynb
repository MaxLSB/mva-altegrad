{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuVouapRmjEW"
      },
      "source": [
        "<center><h2>ALTeGraD 2024<br>Lab Session 1: HAN</h2><h3>Hierarchical Attention Network Using GRU</h3> 8 / 10 / 2024<br> Dr. Guokan Shang, Yang Zhang<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> Maxence Lasbordes\n",
        "\n",
        "\n",
        "</center>\n",
        "In this lab, you will get familiar with recurrent neural networks (RNNs), self-attention, and the HAN architecture <b>(Yang et al. 2016)</b> using PyTorch. In this architecture, sentence embeddings are first individually produced, and a document embedding is then computed from the sentence embeddings.<br>\n",
        "<b>The deadline for this lab is October 15, 2024 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJaSJaIP1xRy"
      },
      "source": [
        "### = = = = =  Attention Layer = = = = =\n",
        "In thi section, you will fill the gaps in the code to implement the self-attention layer. This layer will be used later to define the HAN architecture. The basic idea behind attention is that rather than considering the last annotation $h_T$ as a summary of the entire sequence, which is prone to information loss, the annotations at <i>all</i> time steps are used.\n",
        "The self-attention mechanism computes a weighted sum of the annotations, where the weights are determined by trainable parameters. Refer to <b>section 2.2</b> in the handout for the theoretical part, it will be needed to finish the first task.\n",
        "\n",
        "#### <b>Task 1:</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yoM7H0KQncpF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class AttentionWithContext(nn.Module):\n",
        "    \"\"\"\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_shape, return_coefficients=False, bias=True):\n",
        "        super(AttentionWithContext, self).__init__()\n",
        "        self.return_coefficients = return_coefficients\n",
        "\n",
        "        self.W = nn.Linear(input_shape, input_shape, bias=bias)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.u = nn.Linear(input_shape, 1, bias=False)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.W.weight.data.uniform_(-initrange, initrange)\n",
        "        self.W.bias.data.uniform_(-initrange, initrange)\n",
        "        self.u.weight.data.uniform_(-initrange, initrange)\n",
        "    \n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        # do not pass the mask to the next layers\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "    \n",
        "    def forward(self, x, mask=None):\n",
        "        uit = self.W(x) # compute uit = W . x  where x represents ht\n",
        "        uit = self.tanh(uit)\n",
        "        ait = self.u(uit)\n",
        "        a = torch.exp(ait)\n",
        "        \n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            a = a*mask.double()\n",
        "        \n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        eps = 1e-9\n",
        "        a = a / (torch.sum(a, axis=1, keepdim=True) + eps)\n",
        "        weighted_input = torch.sum(a * x, axis=1) # compute the attentional vector\n",
        "        if self.return_coefficients:\n",
        "            return  [weighted_input, a] ### [attentional vector, coefficients] ### use torch.sum to compute s\n",
        "        else:\n",
        "            return  weighted_input ### attentional vector only ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgTP6GrOHlss"
      },
      "source": [
        "### = = = = = Parameters = = = = =\n",
        "In this section, we define the parameters to use in our training. Such as data path, the embedding dimention <b>d</b>, the GRU layer dimensionality <b>n_units</b>, etc..<br>\n",
        "The parameter <b>device</b> is used to train the model on GPU if it is available. for this purpose, if you are using Google Colab, switch your runtime to a GPU runtime to train the model with a maximum speed.<br>\n",
        "<b>Bonus question:</b> What is the purpose of the parameter <i>my_patience</i>?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "czsVjxgYnczb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import json\n",
        "import operator\n",
        "import numpy as np\n",
        "\n",
        "path_root = ''\n",
        "path_to_data = path_root + 'data/'\n",
        "\n",
        "d = 30 # dimensionality of word embeddings\n",
        "n_units = 50 # RNN layer dimensionality\n",
        "drop_rate = 0.5 # dropout\n",
        "mfw_idx = 2 # index of the most frequent words in the dictionary \n",
        "            # 0 is for the special padding token\n",
        "            # 1 is for the special out-of-vocabulary token\n",
        "\n",
        "padding_idx = 0\n",
        "oov_idx = 1\n",
        "batch_size = 64\n",
        "nb_epochs = 15\n",
        "my_patience = 2 # for early stopping strategy\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Vot_C7Hlst"
      },
      "source": [
        "### = = = = = Data Loading = = = = =\n",
        "In this section we will use first <b>wget</b> to download the data the we will load it using numpy in the first cell. While in the second cell, we will use these data to define our Pytorch data loader. Note that the data is already preprocessed, tokenized and padded.<br><br>\n",
        "<b>Note: if you are running your notebook on Windows or on MacOS, <i>wget</i> will probably not work if you did not install it manually. In this case, use the provided link to download the data and change the <i>path_to_data</i> in the <i>Parameters</i> section accordingly. Otherwise, you will face no problem on Ubuntu and Google Colab.</b>\n",
        "\n",
        "#### <b>Task 2.1:</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UD6hRh0OHlst"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' n'est pas reconnu en tant que commande interne\n",
            "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "url = \"https://onedrive.live.com/download?cid=AE69638675180117&resid=AE69638675180117%2199289&authkey=AHgxt3xmgG0Fu5A\"\n",
        "output_file = \"data.zip\"\n",
        "urllib.request.urlretrieve(url, output_file)\n",
        "\n",
        "!unzip data.zip\n",
        "\n",
        "my_docs_array_train = np.load(path_to_data + 'docs_train.npy')\n",
        "my_docs_array_test = np.load(path_to_data + 'docs_test.npy')\n",
        "\n",
        "my_labels_array_train = np.load(path_to_data + 'labels_train.npy')\n",
        "my_labels_array_test = np.load(path_to_data + 'labels_test.npy')\n",
        "\n",
        "# load dictionary of word indexes (sorted by decreasing frequency across the corpus)\n",
        "with open(path_to_data + 'word_to_index.json', 'r') as my_file:\n",
        "    word_to_index = json.load(my_file)\n",
        "\n",
        "# invert mapping\n",
        "index_to_word = {v: k for k, v in word_to_index.items()} # (use a dict comprehension) ###\n",
        "input_size = my_docs_array_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DpsCvmaiJfZc"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset_(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.documents = x\n",
        "        self.labels = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        document = self.documents[index]\n",
        "        label = self.labels[index] \n",
        "        sample = {\n",
        "            \"document\": torch.tensor(document),\n",
        "            \"label\": torch.tensor(label),\n",
        "            }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def get_loader(x, y, batch_size=32):\n",
        "    dataset = Dataset_(x, y)\n",
        "    data_loader = DataLoader(dataset=dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            pin_memory=True,\n",
        "                            drop_last=True,\n",
        "                            )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rzqEGOdHlst"
      },
      "source": [
        "### = = = = = Defining Architecture = = = = =\n",
        "In this section, we define the HAN architecture. We start with <i>AttentionBiGRU</i> module in order to define the sentence encoder (check Figure 3 in the handout). Then, we define the <i>TimeDistributed</i> module to allow us to forward our input (batch of document) as to the sentence encoder as <b>batch of sentences</b>, where each sentence in the document will be considered as a time step. This module also reshape the output to a batch of timesteps representations per document. Finally we define the <b>HAN</b> architecture using <i>TimeDistributed</i>, <i>AttentionWithContext</i> and <i>GRU</i>.\n",
        "\n",
        "#### <b>Task 2.2:</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AMj9j1_pHlst"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AttentionBiGRU(nn.Module):\n",
        "    def __init__(self, input_shape, n_units, index_to_word, dropout=0):\n",
        "        super(AttentionBiGRU, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(index_to_word) + 2, d, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(drop_rate)\n",
        "        self.gru = nn.GRU(input_size=d,\n",
        "                          hidden_size=n_units,\n",
        "                          num_layers=1,\n",
        "                          bias=True,\n",
        "                          batch_first=True,\n",
        "                          bidirectional=True)\n",
        "        self.attention = AttentionWithContext(n_units * 2, # the input shape for the attention layer\n",
        "                                              return_coefficients=True)\n",
        "\n",
        "\n",
        "    def forward(self, sent_ints):\n",
        "        sent_wv = self.embedding(sent_ints)\n",
        "        sent_wv_dr = self.dropout(sent_wv)\n",
        "        sent_wa, _ = self.gru(sent_wv_dr) # RNN layer\n",
        "        sent_att_vec, word_att_coeffs = self.attention(sent_wa) # attentional vector for the sent\n",
        "        sent_att_vec_dr = self.dropout(sent_att_vec)     \n",
        "        return sent_att_vec_dr, word_att_coeffs\n",
        "\n",
        "class TimeDistributed(nn.Module):\n",
        "    def __init__(self, module, batch_first=False):\n",
        "        super(TimeDistributed, self).__init__()\n",
        "        self.module = module\n",
        "        self.batch_first = batch_first\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.size()) <= 2:\n",
        "            return self.module(x)\n",
        "        # Squash samples and timesteps into a single axis\n",
        "        x_reshape = x.contiguous().view(-1, x.size(-1))  # (samples * timesteps, input_size) (448, 30)\n",
        "        sent_att_vec_dr, word_att_coeffs = self.module(x_reshape)\n",
        "        # We have to reshape the output\n",
        "        if self.batch_first:\n",
        "            sent_att_vec_dr = sent_att_vec_dr.contiguous().view(x.size(0), -1, sent_att_vec_dr.size(-1))  # (samples, timesteps, output_size)\n",
        "            word_att_coeffs = word_att_coeffs.contiguous().view(x.size(0), -1, word_att_coeffs.size(-1))  # (samples, timesteps, output_size)\n",
        "        else:\n",
        "            sent_att_vec_dr = sent_att_vec_dr.view(-1, x.size(1), sent_att_vec_dr.size(-1))  # (timesteps, samples, output_size)\n",
        "            word_att_coeffs = word_att_coeffs.view(-1, x.size(1), word_att_coeffs.size(-1))  # (timesteps, samples, output_size)\n",
        "        return sent_att_vec_dr, word_att_coeffs      \n",
        "\n",
        "class HAN(nn.Module):\n",
        "    def __init__(self, input_shape, n_units, index_to_word, dropout=0):\n",
        "        super(HAN, self).__init__()\n",
        "        self.encoder = AttentionBiGRU(input_shape, n_units, index_to_word, dropout)\n",
        "        self.timeDistributed = TimeDistributed(self.encoder, True)\n",
        "        self.dropout = nn.Dropout(drop_rate)\n",
        "        self.gru = nn.GRU(input_size=n_units * 2, # the input shape of GRU layer\n",
        "                          hidden_size=n_units,\n",
        "                          num_layers=1,\n",
        "                          bias=True,\n",
        "                          batch_first=True,\n",
        "                          bidirectional=True)\n",
        "        self.attention = AttentionWithContext(n_units * 2, # the input shape of between-sentence attention layer\n",
        "                                              return_coefficients=True)\n",
        "        self.lin_out = nn.Linear(n_units * 2, # the input size of the last linear layer\n",
        "                                 1)\n",
        "        self.preds = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, doc_ints):\n",
        "        sent_att_vecs_dr, word_att_coeffs = self.timeDistributed(doc_ints) # get sentence representation\n",
        "        doc_sa, _ = self.gru(sent_att_vecs_dr)\n",
        "        doc_att_vec, sent_att_coeffs = self.attention(doc_sa)\n",
        "        doc_att_vec_dr = self.dropout(doc_att_vec)\n",
        "        doc_att_vec_dr = self.lin_out(doc_att_vec_dr)\n",
        "        return self.preds(doc_att_vec_dr), word_att_coeffs, sent_att_coeffs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgreR5AcHlst"
      },
      "source": [
        "### = = = = = Training = = = = =\n",
        "In this section, we have two code cells. In the first one, we define our evaluation function to compute the training and validation accuracies. While in the second one, we define our model, loss and optimizer and train the model over <i>nb_epochs</i>.<br>\n",
        "<b>Bonus task:</b> use <a href=\"https://pytorch.org/tutorials/recipes/recipes/tensorboard_with_pytorch.html\" target=\"_blank\">tensorboard</a> to visualize the loss and the validation accuray during the training.\n",
        "\n",
        "#### <b>Task 2.3:</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ztF2Lkie-C25"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy(data_loader, verbose=True):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    ncorrect = ntotal = 0\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(data_loader):\n",
        "            # inference \n",
        "            output = model(data[\"document\"].to(device))[0] \n",
        "            output = output[:, -1] # only last vector\n",
        "            # total number of examples\n",
        "            ntotal +=  output.shape[0]\n",
        "            # number of correct predictions \n",
        "            predictions = torch.round(output)\n",
        "            ncorrect += torch.sum(predictions == data[\"label\"].to(device)) # number of correct prediction - hint: use torch.sum \n",
        "        acc = ncorrect.item() / ntotal\n",
        "        if verbose:\n",
        "          print(\"validation accuracy: {:3.2f}\".format(acc*100))\n",
        "        return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RRYiKhZEEidb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 390/390 [00:17<00:00, 22.88batch/s, accuracy=60, loss=0.655]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 1 Complete: Avg. Loss: 0.6549, Validation Accuracy: 69.42%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 390/390 [00:17<00:00, 22.75batch/s, accuracy=70.4, loss=0.567]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 2 Complete: Avg. Loss: 0.5673, Validation Accuracy: 75.81%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 390/390 [00:15<00:00, 24.83batch/s, accuracy=75.3, loss=0.506]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 3 Complete: Avg. Loss: 0.5055, Validation Accuracy: 78.78%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 390/390 [00:16<00:00, 24.13batch/s, accuracy=78.2, loss=0.46] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 4 Complete: Avg. Loss: 0.4601, Validation Accuracy: 80.54%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 390/390 [00:15<00:00, 24.50batch/s, accuracy=80.1, loss=0.428]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 5 Complete: Avg. Loss: 0.4284, Validation Accuracy: 80.33%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 390/390 [00:16<00:00, 24.15batch/s, accuracy=81.8, loss=0.401]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 6 Complete: Avg. Loss: 0.4012, Validation Accuracy: 82.29%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 390/390 [00:16<00:00, 24.21batch/s, accuracy=82.7, loss=0.387]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 7 Complete: Avg. Loss: 0.3867, Validation Accuracy: 83.07%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 390/390 [00:16<00:00, 24.37batch/s, accuracy=84, loss=0.365]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 8 Complete: Avg. Loss: 0.3653, Validation Accuracy: 83.76%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 390/390 [00:15<00:00, 24.56batch/s, accuracy=84.9, loss=0.348]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 9 Complete: Avg. Loss: 0.3483, Validation Accuracy: 84.29%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 390/390 [00:16<00:00, 24.25batch/s, accuracy=85.6, loss=0.333]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 10 Complete: Avg. Loss: 0.3334, Validation Accuracy: 84.44%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 390/390 [00:16<00:00, 23.82batch/s, accuracy=86.2, loss=0.322]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 11 Complete: Avg. Loss: 0.3215, Validation Accuracy: 84.68%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 390/390 [00:16<00:00, 24.03batch/s, accuracy=87, loss=0.307]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 12 Complete: Avg. Loss: 0.3066, Validation Accuracy: 84.76%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 390/390 [00:16<00:00, 24.26batch/s, accuracy=87.6, loss=0.298]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 13 Complete: Avg. Loss: 0.2979, Validation Accuracy: 84.38%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 390/390 [00:16<00:00, 24.28batch/s, accuracy=87.8, loss=0.291]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 14 Complete: Avg. Loss: 0.2909, Validation Accuracy: 84.85%\n",
            "Validation accuracy improved, saving model...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 390/390 [00:16<00:00, 24.21batch/s, accuracy=88.6, loss=0.275]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===> Epoch 15 Complete: Avg. Loss: 0.2745, Validation Accuracy: 85.09%\n",
            "Validation accuracy improved, saving model...\n",
            "\n",
            "Loading best checkpoint...\n",
            "done.\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model = HAN(input_size, n_units, index_to_word)\n",
        "model.to(device)\n",
        "model = model.double()\n",
        "lr = 0.001  # learning rate\n",
        "criterion = torch.nn.BCELoss()# fill the gap, use Binary cross entropy from torch.nn: https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #fill me\n",
        "\n",
        "def train(x_train=my_docs_array_train,\n",
        "          y_train=my_labels_array_train,\n",
        "          x_test=my_docs_array_test,\n",
        "          y_test=my_labels_array_test,\n",
        "          word_dict=index_to_word,\n",
        "          batch_size=batch_size):\n",
        "  \n",
        "    train_data = get_loader(x_train, y_train, batch_size)\n",
        "    test_data = get_loader(my_docs_array_test, my_labels_array_test, batch_size)\n",
        "\n",
        "    best_validation_acc = 0.0\n",
        "    p = 0 # patience\n",
        "\n",
        "    for epoch in range(1, nb_epochs + 1): \n",
        "        losses = []\n",
        "        accuracies = []\n",
        "        with tqdm(train_data, unit=\"batch\") as tepoch:\n",
        "            for idx, data in enumerate(tepoch):\n",
        "                tepoch.set_description(f\"Epoch {epoch}\")\n",
        "                model.train()\n",
        "                optimizer.zero_grad()\n",
        "                input = data['document'].to(device)\n",
        "                label = data['label'].to(device)\n",
        "                label = label.double()\n",
        "                output = model.forward(input)[0]\n",
        "                output = output[:, -1]\n",
        "                loss = criterion(output, label) # compute the loss\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient \n",
        "                optimizer.step()\n",
        "\n",
        "                losses.append(loss.item())\n",
        "                accuracy = torch.sum(torch.round(output) == label).item() / batch_size\n",
        "                accuracies.append(accuracy)\n",
        "                tepoch.set_postfix(loss=sum(losses)/len(losses), accuracy=100. * sum(accuracies)/len(accuracies))\n",
        "\n",
        "        # train_acc = evaluate_accuracy(train_data, False)\n",
        "        test_acc = evaluate_accuracy(test_data, False)\n",
        "        print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}, Validation Accuracy: {:3.2f}%\"\n",
        "              .format(epoch, sum(losses)/len(losses), 100.*test_acc))\n",
        "        if test_acc >= best_validation_acc:\n",
        "            best_validation_acc = test_acc\n",
        "            print(\"Validation accuracy improved, saving model...\")\n",
        "            torch.save(model.state_dict(), './best_model.pt')\n",
        "            p = 0\n",
        "            print()\n",
        "        else:\n",
        "            p += 1\n",
        "            if p==my_patience:\n",
        "                print(\"Validation accuracy did not improve for {} epochs, stopping training...\".format(my_patience))\n",
        "    print(\"Loading best checkpoint...\")    \n",
        "    model.load_state_dict(torch.load('./best_model.pt'))\n",
        "    model.eval()\n",
        "    print('done.')\n",
        "\n",
        "train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvyr8B5QHlst"
      },
      "source": [
        "### = = = = = Extraction of Attention Coefficients = = = = =\n",
        "In this section, we will extract and display the attention coefficients on two levels: sentence level and word level. To do so, we will extract the corresponding weights from our model.\n",
        "#### <b>Task 3:</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UVr8cS4MHlst"
      },
      "outputs": [],
      "source": [
        "# select last review:\n",
        "my_review = my_docs_array_test[-1:,:,:]\n",
        " \n",
        "# convert integer review to text:\n",
        "index_to_word[1] = 'OOV'\n",
        "my_review_text = [[index_to_word[idx] for idx in sent if idx in index_to_word] for sent in my_review.tolist()[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHDJ7JiqHlsu"
      },
      "source": [
        "###   &emsp;&emsp;  = = = = = Attention Over Sentences in the Document = = = = ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yooWg3kkHlsu",
        "outputId": "2421291a-c557-46a9-8f75-74c998053f74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.46 There 's a sign on The Lost Highway that says : OOV SPOILERS OOV ( but you already knew that , did n't you ? )\n",
            "3.86 Since there 's a great deal of people that apparently did not get the point of this movie , I 'd like to contribute my interpretation of why the plot\n",
            "3.92 As others have pointed out , one single viewing of this movie is not sufficient .\n",
            "3.81 If you have the DVD of MD , you can OOV ' by looking at David Lynch 's 'Top 10 OOV to OOV MD ' ( but only upon second\n",
            "2.99 ; ) First of all , Mulholland Drive is downright brilliant .\n",
            "3.88 A masterpiece .\n",
            "11.15 This is the kind of movie that refuse to leave your head .\n"
          ]
        }
      ],
      "source": [
        "sent_coeffs = model(torch.tensor(my_review, dtype=torch.long).to(device))[1]  # get sentence attention coeffs by passing the review to the model - (you need to convert the inout torch tensor)\n",
        "sent_coeffs = sent_coeffs[0,:,:]\n",
        "\n",
        "for elt in zip(sent_coeffs[:,0].tolist(),[' '.join(elt) for elt in my_review_text]):\n",
        "    print(round(elt[0]*100,2),elt[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rII-DNrKHlsu"
      },
      "source": [
        "### &emsp;&emsp; = = = = = Attention Over Words in Each Sentence = = = = ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyFjAga6Hlsu",
        "outputId": "d9640e73-a3a1-4745-b215-d55470036a3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('There', 0.1045705536642164)\n",
            "(\"'s\", 0.03858370151984117)\n",
            "('a', 0.0392042826803436)\n",
            "('sign', 0.03814042103496396)\n",
            "('on', 0.029934298314460886)\n",
            "('The', 0.0387681825126758)\n",
            "('Lost', 0.11154415516443415)\n",
            "('Highway', 0.11651427447516047)\n",
            "('that', 0.027415843285533318)\n",
            "('says', 0.02331106835939643)\n",
            "(':', 0.022105039959378913)\n",
            "('OOV', 0.016426020689612235)\n",
            "('SPOILERS', 0.016216614341117756)\n",
            "('OOV', 0.014256490513048949)\n",
            "('(', 0.016515573146621082)\n",
            "('but', 0.02845134917424695)\n",
            "('you', 0.029231183113701178)\n",
            "('already', 0.029084088232689348)\n",
            "('knew', 0.03844553709847756)\n",
            "('that', 0.03240908898995247)\n",
            "(',', 0.02077464741471928)\n",
            "('did', 0.021311235198298393)\n",
            "(\"n't\", 0.021398270507720484)\n",
            "('you', 0.020053389129359438)\n",
            "('?', 0.021742973485714603)\n",
            "(')', 0.015487138887420773)\n",
            "= = = =\n",
            "('Since', 0.06703246620784391)\n",
            "('there', 0.053487901231653374)\n",
            "(\"'s\", 0.05068707040175416)\n",
            "('a', 0.04894479762508611)\n",
            "('great', 0.1716747224996056)\n",
            "('deal', 0.04351068392035274)\n",
            "('of', 0.020844235179286554)\n",
            "('people', 0.025803887976470773)\n",
            "('that', 0.019817379997411993)\n",
            "('apparently', 0.02719193841079717)\n",
            "('did', 0.02363220376974256)\n",
            "('not', 0.02170016057511693)\n",
            "('get', 0.018619273239358195)\n",
            "('the', 0.015242999027336723)\n",
            "('point', 0.0455186258252191)\n",
            "('of', 0.026056542219541196)\n",
            "('this', 0.0403285280578292)\n",
            "('movie', 0.034664186686680636)\n",
            "(',', 0.01778227426344067)\n",
            "('I', 0.018012374829954474)\n",
            "(\"'d\", 0.03367674061045744)\n",
            "('like', 0.025956159761280358)\n",
            "('to', 0.021558773727173325)\n",
            "('contribute', 0.020731666948984113)\n",
            "('my', 0.016612400318898837)\n",
            "('interpretation', 0.01719428050913676)\n",
            "('of', 0.013874552745965675)\n",
            "('why', 0.014507013029466906)\n",
            "('the', 0.012997606453281884)\n",
            "('plot', 0.03233855384744901)\n",
            "= = = =\n",
            "('As', 0.04584605185091087)\n",
            "('others', 0.03846018489489406)\n",
            "('have', 0.0215504772574501)\n",
            "('pointed', 0.02954501916983016)\n",
            "('out', 0.030319407099247554)\n",
            "(',', 0.016052375136079097)\n",
            "('one', 0.027057513827802866)\n",
            "('single', 0.05031972809572468)\n",
            "('viewing', 0.12027194016493144)\n",
            "('of', 0.04207257333268238)\n",
            "('this', 0.04158606536478913)\n",
            "('movie', 0.030871234735467195)\n",
            "('is', 0.042422079422086104)\n",
            "('not', 0.08501827959054896)\n",
            "('sufficient', 0.10192897300306605)\n",
            "('.', 0.021626735075340728)\n",
            "= = = =\n",
            "('If', 0.06538488753469521)\n",
            "('you', 0.04477305893029282)\n",
            "('have', 0.02884225971529817)\n",
            "('the', 0.03210499320142556)\n",
            "('DVD', 0.05104895529545628)\n",
            "('of', 0.034463067905697864)\n",
            "('MD', 0.03677569767925139)\n",
            "(',', 0.015846291118276467)\n",
            "('you', 0.022126774923686598)\n",
            "('can', 0.01928220132929194)\n",
            "('OOV', 0.01967715614901565)\n",
            "(\"'\", 0.021744383461444874)\n",
            "('by', 0.03381309210183522)\n",
            "('looking', 0.04362388392507153)\n",
            "('at', 0.030156256753126123)\n",
            "('David', 0.03145775386491795)\n",
            "('Lynch', 0.0314812026923397)\n",
            "(\"'s\", 0.029938514592730902)\n",
            "(\"'Top\", 0.026984021660049158)\n",
            "('10', 0.021765799323572)\n",
            "('OOV', 0.026019542332461596)\n",
            "('to', 0.027057736964151723)\n",
            "('OOV', 0.032022663161550766)\n",
            "('MD', 0.08752572474892814)\n",
            "(\"'\", 0.02211886679542556)\n",
            "('(', 0.01883709333578656)\n",
            "('but', 0.03143478902356073)\n",
            "('only', 0.045183556769789156)\n",
            "('upon', 0.03573710522785973)\n",
            "('second', 0.03277266936205182)\n",
            "= = = =\n",
            "(';', 0.03895377747335872)\n",
            "(')', 0.019671907522950366)\n",
            "('First', 0.033387452349476286)\n",
            "('of', 0.017696932616761685)\n",
            "('all', 0.01619791772368216)\n",
            "(',', 0.012067222454501262)\n",
            "('Mulholland', 0.01487351923111921)\n",
            "('Drive', 0.01445000245849506)\n",
            "('is', 0.04801196509934249)\n",
            "('downright', 0.32491301191171845)\n",
            "('brilliant', 0.2001470199218852)\n",
            "('.', 0.028308729267517423)\n",
            "= = = =\n",
            "('A', 0.12497625844191826)\n",
            "('masterpiece', 0.2291812898258948)\n",
            "('.', 0.0450588186516212)\n",
            "= = = =\n",
            "('This', 0.08001819870949611)\n",
            "('is', 0.0694735209102141)\n",
            "('the', 0.09161957324720464)\n",
            "('kind', 0.17324311157677383)\n",
            "('of', 0.0699414636989574)\n",
            "('movie', 0.04106339336855779)\n",
            "('that', 0.038117871254362494)\n",
            "('refuse', 0.029598466979438378)\n",
            "('to', 0.028688481437013018)\n",
            "('leave', 0.02866746225767879)\n",
            "('your', 0.018750516358122204)\n",
            "('head', 0.02030918475716617)\n",
            "('.', 0.016620715537821767)\n",
            "= = = =\n",
            "('Highway', 0.11651427447516047)\n",
            "('Lost', 0.11154415516443415)\n",
            "('There', 0.1045705536642164)\n",
            "('a', 0.0392042826803436)\n",
            "('The', 0.0387681825126758)\n",
            "(\"'s\", 0.03858370151984117)\n",
            "('knew', 0.03844553709847756)\n",
            "('sign', 0.03814042103496396)\n",
            "('that', 0.03240908898995247)\n",
            "('on', 0.029934298314460886)\n",
            "('you', 0.029231183113701178)\n",
            "('already', 0.029084088232689348)\n",
            "('but', 0.02845134917424695)\n",
            "('that', 0.027415843285533318)\n",
            "('says', 0.02331106835939643)\n",
            "(':', 0.022105039959378913)\n",
            "('?', 0.021742973485714603)\n",
            "(\"n't\", 0.021398270507720484)\n",
            "('did', 0.021311235198298393)\n",
            "(',', 0.02077464741471928)\n",
            "('you', 0.020053389129359438)\n",
            "('(', 0.016515573146621082)\n",
            "('OOV', 0.016426020689612235)\n",
            "('SPOILERS', 0.016216614341117756)\n",
            "(')', 0.015487138887420773)\n",
            "('OOV', 0.014256490513048949)\n",
            "= = = =\n",
            "('great', 0.1716747224996056)\n",
            "('Since', 0.06703246620784391)\n",
            "('there', 0.053487901231653374)\n",
            "(\"'s\", 0.05068707040175416)\n",
            "('a', 0.04894479762508611)\n",
            "('point', 0.0455186258252191)\n",
            "('deal', 0.04351068392035274)\n",
            "('this', 0.0403285280578292)\n",
            "('movie', 0.034664186686680636)\n",
            "(\"'d\", 0.03367674061045744)\n",
            "('plot', 0.03233855384744901)\n",
            "('apparently', 0.02719193841079717)\n",
            "('of', 0.026056542219541196)\n",
            "('like', 0.025956159761280358)\n",
            "('people', 0.025803887976470773)\n",
            "('did', 0.02363220376974256)\n",
            "('not', 0.02170016057511693)\n",
            "('to', 0.021558773727173325)\n",
            "('of', 0.020844235179286554)\n",
            "('contribute', 0.020731666948984113)\n",
            "('that', 0.019817379997411993)\n",
            "('get', 0.018619273239358195)\n",
            "('I', 0.018012374829954474)\n",
            "(',', 0.01778227426344067)\n",
            "('interpretation', 0.01719428050913676)\n",
            "('my', 0.016612400318898837)\n",
            "('the', 0.015242999027336723)\n",
            "('why', 0.014507013029466906)\n",
            "('of', 0.013874552745965675)\n",
            "('the', 0.012997606453281884)\n",
            "= = = =\n",
            "('viewing', 0.12027194016493144)\n",
            "('sufficient', 0.10192897300306605)\n",
            "('not', 0.08501827959054896)\n",
            "('single', 0.05031972809572468)\n",
            "('As', 0.04584605185091087)\n",
            "('is', 0.042422079422086104)\n",
            "('of', 0.04207257333268238)\n",
            "('this', 0.04158606536478913)\n",
            "('others', 0.03846018489489406)\n",
            "('movie', 0.030871234735467195)\n",
            "('out', 0.030319407099247554)\n",
            "('pointed', 0.02954501916983016)\n",
            "('one', 0.027057513827802866)\n",
            "('.', 0.021626735075340728)\n",
            "('have', 0.0215504772574501)\n",
            "(',', 0.016052375136079097)\n",
            "= = = =\n",
            "('MD', 0.08752572474892814)\n",
            "('If', 0.06538488753469521)\n",
            "('DVD', 0.05104895529545628)\n",
            "('only', 0.045183556769789156)\n",
            "('you', 0.04477305893029282)\n",
            "('looking', 0.04362388392507153)\n",
            "('MD', 0.03677569767925139)\n",
            "('upon', 0.03573710522785973)\n",
            "('of', 0.034463067905697864)\n",
            "('by', 0.03381309210183522)\n",
            "('second', 0.03277266936205182)\n",
            "('the', 0.03210499320142556)\n",
            "('OOV', 0.032022663161550766)\n",
            "('Lynch', 0.0314812026923397)\n",
            "('David', 0.03145775386491795)\n",
            "('but', 0.03143478902356073)\n",
            "('at', 0.030156256753126123)\n",
            "(\"'s\", 0.029938514592730902)\n",
            "('have', 0.02884225971529817)\n",
            "('to', 0.027057736964151723)\n",
            "(\"'Top\", 0.026984021660049158)\n",
            "('OOV', 0.026019542332461596)\n",
            "('you', 0.022126774923686598)\n",
            "(\"'\", 0.02211886679542556)\n",
            "('10', 0.021765799323572)\n",
            "(\"'\", 0.021744383461444874)\n",
            "('OOV', 0.01967715614901565)\n",
            "('can', 0.01928220132929194)\n",
            "('(', 0.01883709333578656)\n",
            "(',', 0.015846291118276467)\n",
            "= = = =\n",
            "('downright', 0.32491301191171845)\n",
            "('brilliant', 0.2001470199218852)\n",
            "('is', 0.04801196509934249)\n",
            "(';', 0.03895377747335872)\n",
            "('First', 0.033387452349476286)\n",
            "('.', 0.028308729267517423)\n",
            "(')', 0.019671907522950366)\n",
            "('of', 0.017696932616761685)\n",
            "('all', 0.01619791772368216)\n",
            "('Mulholland', 0.01487351923111921)\n",
            "('Drive', 0.01445000245849506)\n",
            "(',', 0.012067222454501262)\n",
            "= = = =\n",
            "('masterpiece', 0.2291812898258948)\n",
            "('A', 0.12497625844191826)\n",
            "('.', 0.0450588186516212)\n",
            "= = = =\n",
            "('kind', 0.17324311157677383)\n",
            "('the', 0.09161957324720464)\n",
            "('This', 0.08001819870949611)\n",
            "('of', 0.0699414636989574)\n",
            "('is', 0.0694735209102141)\n",
            "('movie', 0.04106339336855779)\n",
            "('that', 0.038117871254362494)\n",
            "('refuse', 0.029598466979438378)\n",
            "('to', 0.028688481437013018)\n",
            "('leave', 0.02866746225767879)\n",
            "('head', 0.02030918475716617)\n",
            "('your', 0.018750516358122204)\n",
            "('.', 0.016620715537821767)\n",
            "= = = =\n"
          ]
        }
      ],
      "source": [
        "word_coeffs = model(torch.tensor(my_review, dtype=torch.long).to(device))[1]  # get words attention coeffs by passing the review to the model - (you need to convert the inout torch tensor)\n",
        "\n",
        "word_coeffs_list = word_coeffs.reshape(7,30).tolist()\n",
        "\n",
        "# match text and coefficients:\n",
        "text_word_coeffs = [list(zip(words,word_coeffs_list[idx][:len(words)])) for idx,words in enumerate(my_review_text)]\n",
        "\n",
        "for sent in text_word_coeffs:\n",
        "    [print(elt) for elt in sent]\n",
        "    print('= = = =')\n",
        "\n",
        "# sort words by importance within each sentence:\n",
        "text_word_coeffs_sorted = [sorted(elt,key=operator.itemgetter(1),reverse=True) for elt in text_word_coeffs]\n",
        "\n",
        "for sent in text_word_coeffs_sorted:\n",
        "    [print(elt) for elt in sent]\n",
        "    print('= = = =')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bonus: plotting the word importance:\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_word_importance(text_word_coeffs_sorted, sentence_index=0):\n",
        "    sent = text_word_coeffs_sorted[sentence_index]\n",
        "    words, coeffs = zip(*sent)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.barh(words, coeffs, color='skyblue')\n",
        "    plt.xlabel('Attention Coefficients')\n",
        "    plt.title(f'Word Importance in Sentence {sentence_index + 1}')\n",
        "    plt.xlim(0, max(coeffs) + 0.1)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.savefig('word_importance')\n",
        "    plt.show()\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot word importance for the first sentence\n",
        "plot_word_importance(text_word_coeffs_sorted, sentence_index=0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
